{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## INF-578. Machine Learning. Tarea 2.\n",
    "# Métodos Lineales para Clasificación\n",
    "\n",
    "## Álvaro Salinas -  Camilo Valenzuela\n",
    "\n",
    "## 17 de Noviembre de 2017\n",
    "\n",
    "### Tabla de Contenidos\n",
    "\n",
    "* [Librerías Necesarias](#libs)\n",
    "* [Pregunta 1](#1)\n",
    "    * [1.a](#1a)\n",
    "    * [1.b](#1b)\n",
    "    * [1.c](#1c)\n",
    "    * [1.d](#1d)\n",
    "    * [1.e](#1e)\n",
    "    * [1.f](#1f)\n",
    "    * [1.g](#1g)\n",
    "    * [1.h](#1h)\n",
    "    * [1.i](#1i)\n",
    "* [Pregunta 2](#2)\n",
    "    * [2.a](#2a)\n",
    "    * [2.b](#2b)\n",
    "    * [2.c](#2c)\n",
    "    * [2.d](#2d)\n",
    "    * [2.e](#2e)\n",
    "    * [2.f](#2f)\n",
    "    * [2.g](#2g)\n",
    "* [Pregunta 3](#3)\n",
    "    * [3.a](#3a)\n",
    "    * [3.b](#3b)\n",
    "    * [3.c](#3c)\n",
    "    * [3.d](#3d)\n",
    "    * [3.e](#3e)\n",
    "    * [3.f](#3f)\n",
    "    * [3.g](#3g)\n",
    "\n",
    "<div id='libs' />\n",
    "### Librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='1' />\n",
    "### 1. Reducción de Dimensionalidad para Clasificación\n",
    "\n",
    "<div id='1a' />\n",
    "##### (a) Construya un dataframe con los datos a analizar descargando los datos desde la URL. Determine cuántos registros contiene el conjunto de entrenamiento y cuántos el conjunto de pruebas. Determine además el número promedio de palabras por ítem en cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "train_data_url = \"http://statweb.stanford.edu/~hastie/ElemStatLearn/datasets/vowel.train\"\n",
    "test_data_url = \"http://statweb.stanford.edu/~hastie/ElemStatLearn/datasets/vowel.test\"\n",
    "train_data_f = urllib.urlretrieve(train_data_url, \"train_data.csv\")\n",
    "test_data_f = urllib.urlretrieve(test_data_url, \"test_data.csv\")\n",
    "train_df = pd.DataFrame.from_csv('train_data.csv',header=0,index_col=0)\n",
    "test_df = pd.DataFrame.from_csv('test_data.csv',header=0,index_col=0)\n",
    "train_df.head()\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='1b' />\n",
    "##### (b) Construya matrices $X$ e $y$ que contengan las características y las etiquetas correspondientes a los datos de entrenamiento y pruebas. Normalice apropiadamente los datos antes de empezar a trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = train_df.loc[:,'x.1':'x.10'].values\n",
    "y = train_df.loc[:,'y'].values\n",
    "Scaler = StandardScaler().fit(X)\n",
    "X_std = Scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='1c' />\n",
    "##### (c) Utilizando PCA genere una representación en 2 dimensiones de la data original (10 dimensiones) identificando cada clase con un color distinto (elija una paleta apropiada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sklearn_pca = PCA(n_components=2)\n",
    "Xred_pca = sklearn_pca.fit_transform(X_std)\n",
    "cmap = plt.cm.get_cmap('ChooseAnAppropriatePalette')\n",
    "mclasses=(1,2,3,4,5,6,7,8,9)\n",
    "mcolors = [cmap(i) for i in np.linspace(0,1,10)]\n",
    "plt.figure(figsize=(12, 8))\n",
    "for lab, col in zip(mclasses,mcolors):\n",
    "    plt.scatter(Xred_pca[y==lab, 0],Xred_pca[y==lab, 1],label=lab,c=col)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "leg = plt.legend(loc='upper right', fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='1d' />\n",
    "##### (d) Utilizando LDA genere una representación en 2 dimensiones de la data original (10 dimensiones) identificando cada clase con un color distinto (elija una paleta apropiada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.lda import LDA\n",
    "sklearn_lda = LDA(n_components=2)\n",
    "Xred_lda = sklearn_lda.fit_transform(X_std,y)\n",
    "cmap = plt.cm.get_cmap('ChooseAnAppropriatePalette')\n",
    "mclasses=(1,2,3,4,5,6,7,8,9)\n",
    "mcolors = [cmap(i) for i in np.linspace(0,1,10)]\n",
    "plt.figure(figsize=(12, 8))\n",
    "for lab, col in zip(mclasses,mcolors):\n",
    "    plt.scatter(Xred_lda[y==lab, 0],Xred_lda[y==lab, 1],label=lab,c=col)\n",
    "plt.xlabel('LDA/Fisher Direction 1')\n",
    "plt.ylabel('LDA/Fisher Direction 2')\n",
    "leg = plt.legend(loc='upper right', fancybox=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='1e' />\n",
    "##### (e) Compare cualitativamente los resultados obtenidos en c y d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='1f' />\n",
    "##### (f) Construya un clasificador que determine la clase de un dato $x$ aleatoriamente sin considerar las características sino que solamente la probabilidad a-priori de cada clase. Por ejemplo, si la clase $y = 0$ ocurre el $25\\%$ de las veces, su clasificador debe predecir esta clase para un determinado $x$ con probabilidad $0.25$, independiente de los atributos de $x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='1g' />\n",
    "##### (g) Compare el desempeño de LDA, QDA y un modelo de Vecinos M´as Cercanos ($k$-NN) sin reducir dimensionalidad. ¿Qué técnica se comporta mejor sobre el conjunto de entrenamiento? ¿Sobre el conjunto de pruebas? Describa, utilizando un gráfico, el efecto de cambiar el parámetro de $k$ en el tercer modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "Xtest = test_df.loc[:,'x.1':'x.10'].values\n",
    "ytest = test_df.loc[:,'y'].values\n",
    "X_std_test = Scaler.transform(Xtest)\n",
    "lda_model = LDA()\n",
    "lda_model.fit(X_std,y)\n",
    "print \"-----LDA-----\"\n",
    "print lda_model.score(X_std,y)\n",
    "print lda_model.score(X_std_test,ytest)\n",
    "qda_model = QDA()\n",
    "qda_model.fit(X_std,y)\n",
    "print \"-----QDA-----\"\n",
    "print qda_model.score(X_std,y)\n",
    "print qda_model.score(X_std_test,ytest)\n",
    "print \"-----KNN-----\"\n",
    "knn_scores_training = []\n",
    "knn_scores_testing = []\n",
    "k = range(1,51)\n",
    "for c in k:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=c)\n",
    "    knn_model.fit(X_std,y)\n",
    "    knn_scores_training.append(knn_model.score(X_std,y))\n",
    "    knn_scores_testing.append(knn_model.score(X_std_test,ytest))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(211)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Training/Testing\")\n",
    "plt.plot(k,knn_scores_training, '-o',k,knn_scores_testing, '-o')\n",
    "plt.legend((\"Training\", \"Testing\"), loc = \"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='1h' />\n",
    "##### (h) Utilice PCA para generar una representación de la data en $d' = 1, 2, 3, \\dots , 10$ dimensiones. Para cada caso entrene un modelo LDA, QDA y de $k$-NN. Construya un gráfico que muestre cómo evoluciona el error de entrenamiento versus $d'$. Sobreponga a este gráfico el error de pruebas versus $d'$. Concluya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='1i' />\n",
    "##### (i) Utilice LDA para generar una representación de la data en $d' = 1, 2, 3, \\dots , 10$ dimensiones. Para cada caso entrene un modelo LDA, QDA y de $k$-NN. Construya un gráfico que muestre cómo evoluciona el error de entrenamiento versus $d'$. Sobreponga a este gráfico el error de pruebas versus $d'$. Concluya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='2' />\n",
    "### 2. Análisis de Opiniones sobre Películas\n",
    "\n",
    "<div id='2a' />\n",
    "##### (a) Construya un dataframe con los datos a analizar descargando los datos desde la URL local. Determine cuántos registros de cada clase contiene el conjunto de entrenamiento y cuántos el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "train_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.train\"\n",
    "test_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.dev\"\n",
    "train_data_f = urllib.urlretrieve(train_data_url, \"train_data.csv\")\n",
    "test_data_f = urllib.urlretrieve(test_data_url, \"test_data.csv\")\n",
    "ftr = open(\"train_data.csv\", \"r\")\n",
    "fts = open(\"test_data.csv\", \"r\")\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "train_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "train_df['Sentiment'] = pd.to_numeric(train_df['Sentiment'])\n",
    "rows = [line.split(\" \",1) for line in fts.readlines()]\n",
    "test_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "test_df['Sentiment'] = pd.to_numeric(test_df['Sentiment'])\n",
    "print train_df.shape\n",
    "print test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='2b' />\n",
    "##### (b) Construya una función, denominada word_extractor, que devuelva una lista de las palabras contenidas en un determinado un trozo de texto. Incorpore en su función las operaciones de lower-casing y stemming. Pruebe la función con las frases sugeridas en el código, invente otras similares y comente. Compare con los resultados obtenidos si no se hace stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "def word_extractor(text):\n",
    "    ps = PorterStemmer()\n",
    "    commonwords = stopwords.words('english')\n",
    "    commonwords.remove(\"not\")\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)\n",
    "    words = \"\"\n",
    "    wordtokens = [ ps.stem(word.lower()) for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "print word_extractor(\"I love to eat cake\")\n",
    "print word_extractor(\"I love eating cake\")\n",
    "print word_extractor(\"I loved eating the cake\")\n",
    "print word_extractor(\"I do not love eating cake\")\n",
    "print word_extractor(\"I don't love eating cake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='2c' />\n",
    "##### (c) Construya una función, denominada word_extractor2, análoga a la función anterior, pero que lematice las palabras en vez de hacer stemming. Pruebe la función con las frases sugeridas en el código anterior y discuta las diferencias que observa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_extractor2(text):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    commonwords = stopwords.words('english')\n",
    "    commonwords.remove(\"not\")\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)\n",
    "    words = \"\"\n",
    "    wordtokens = [ wordlemmatizer.lemmatize(word.lower()) for word in word_tokenize(text.decode('utf-8','ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords:\n",
    "            words+=\" \"+word\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='2d' />\n",
    "##### (d) Utilizando la función CountVectorizer de la librería sklearn y de acuerdo a las directrices mencionadas en la introducción, genere una representación vectorial del texto de entrenamiento y del conjunto que usaremos para realizar pruebas. Explore el vocabulario utilizado y determine cuáles son las palabras más frecuentes en el conjunto de entrenamiento y pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "dist=list(np.array(features_train.sum(axis=0)).reshape(-1,))\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print count, tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='2e' />\n",
    "##### (e) Construya una función que evalúe el desempeño obtenido por un clasificador genérico en el conjunto de entrenamiento y en el conjunto de pruebas. Utilice y explique las métricas que calcula la función classification_report de la librería sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def score_the_model(model,x,y,xt,yt,text):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1],yt[:-1])\n",
    "    print \"Training Accuracy %s: %f\"%(text,acc_tr)\n",
    "    print \"Test Accuracy %s: %f\"%(text,acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(yt, model.predict(xt), target_names=['+','-']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='2f' />\n",
    "##### (f) Construya una función que entrene/ajuste un clasificador Bayesiano Ingenuo (Binario) (las características no nulas serán tratadas como 1) y mida el error de predicción obtenido sobre los datos de entrenamiento y pruebas. Utilice esta función con las características extraídas en el punto (d). Mida el efecto de filtrar stopwords y de eliminar este paso de pre-procesamiento típico. Determine además, qué representación obtiene un mejor resultado: si aquella obtenida vía lematización o aquella obtenida vía stemming. Finalmente, tome un subconjunto aleatorio de los textos de prueba y analice las predicciones del modelo (explore las predicciones, así como las probabilidades que el clasificador asigna a cada clase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import random\n",
    "def do_NAIVE_BAYES(x,y,xt,yt):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"BernoulliNB\")\n",
    "    return model\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='2g' />\n",
    "##### (g) Construya una función que entrene/ajuste una Máquina de Vectores de Soporte (SVM) Lineal y mida el error de predicción obtenido sobre los datos de entrenamiento y pruebas. Incluya en su función la exploración de diferentes valores del parámetro de regularización C. Discuta el significado y efecto esperado de este parámetro. Utilice la función construida con los atributos extraídos en el punto (d). Mida el efecto de filtrar stopwords y de eliminar este paso de pre-procesamiento típico. Determine además, qué representación obtiene un mejor resultado: si aquella obtenida vía lematización o aquella obtenida vía stemming. Finalmente, tome un subconjunto aleatorio de los textos de prueba y analice las predicciones del modelo (explore las predicciones, así como las probabilidades que el clasificador asigna a cada clase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"C Value: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='3' />\n",
    "###  3. Fraude en transacciones bancarias\n",
    "\n",
    "<div id='3a' />\n",
    "##### (a) Descargue y cargue el archivo, genere un gráfico que compare la cantidad de elementos que hay por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "dt = pd.read_csv(\"creditcard.csv\",header = 0)\n",
    "sns.countplot(\"Class\",data=dt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='3b' />\n",
    "#####  (b) Estandarice el monto de la transacción. ¿Por qué solo estandarizamos un atributo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "dt[\"nAmount\"] = StandardScaler().fit_transform(dt['Amount'].values.reshape(-1, 1))\n",
    "dt.drop([\"Time\",\"Amount\"],axis=1,inplace=True)\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='3c' />\n",
    "##### (c) Defina una función que reciba como input un modelo, los datos de entrenamiento y datos de testeo. Esta función deberá mostrar luego de generar el modelo y haber probado la data de testing una matriz de confusión, junto a sus respectivas métricas. Deberá además mostrar una curva ROC junto al valor del área bajo la curva de esta. Finalmente, responda las siguientes preguntas ¿Qué es una matriz de confusión? ¿Qué métricas se pueden calcular de ésta y cuáles nos serán útiles en este experimento? ¿Qué es una curva ROC y qué relación tiene con la matriz de confusión?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(model,features_train,features_test,labels_train,labels_test):\n",
    "    clf = model\n",
    "    clf.fit(features_train,labels_train.values.ravel())\n",
    "    pred=clf.predict(features_test)\n",
    "    cnf_matrix=confusion_matrix(labels_test,pred)\n",
    "    print \"The recall for this model is: %f\"%(float(cnf_matrix[1,1])/(cnf_matrix[1,1]+cnf_matrix[1,0]))\n",
    "    fig= plt.figure(figsize=(6,3))\n",
    "    print \"TP: %d\"%cnf_matrix[1,1,]\n",
    "    print \"TN: %d\"%cnf_matrix[0,0]\n",
    "    print \"FP: %d\"%cnf_matrix[0,1]\n",
    "    print \"FN: %d\"%cnf_matrix[1,0]\n",
    "    sns.heatmap(cnf_matrix,cmap=\"coolwarm_r\",annot=True,linewidths=0.5)\n",
    "    plt.title(\"Confusion_matrix\")\n",
    "    plt.xlabel(\"Predicted_class\")\n",
    "    plt.ylabel(\"Real class\")\n",
    "    plt.show()\n",
    "    print \"\\n----------Classification Report------------------------------------\"\n",
    "    print classification_report(labels_test,pred)\n",
    "    ''' You have to complete this function, ROC Curve is missing'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='3d' />\n",
    "##### (d) Defina una función que genere un Training y Testing Set de un Dataset cualquiera. Indique qué está haciendo la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def data_prepration(x):\n",
    "    x_features= x.iloc[:,x.columns != \"Class\"]\n",
    "    x_labels=x.iloc[:,x.columns==\"Class\"]\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x_features,x_labels,test_size=0.3)\n",
    "    print \"Length of training data: %d\"%len(x_train)\n",
    "    print \"Length of test data: %d\"%len(x_test)\n",
    "    return(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='3e' />\n",
    "##### (e) Defina una función que realice Undersample. ¿Explique en que consiste esta técnica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(data,times):\n",
    "    fraud_indices= np.array(data[data.Class==1].index)\n",
    "    normal_indices = np.array(data[data.Class==0].index)\n",
    "    Count_Normal_transacation = len(data[data[\"Class\"]==0])\n",
    "    Count_Fraud_transacation = len(data[data[\"Class\"]==1])\n",
    "    Normal_indices_undersample = np.array(np.random.choice(normal_indices,(times*Count_Fraud_transacation),replace=False))\n",
    "    undersample_data= np.concatenate([fraud_indices,Normal_indices_undersample])\n",
    "    undersample_data = data.iloc[undersample_data,:]\n",
    "    normal = (float(len(undersample_data[undersample_data.Class==0]))/len(undersample_data[\"Class\"]))\n",
    "    print \"The normal transacation proportion is : %f\"%normal\n",
    "    fraud = (float(len(undersample_data[undersample_data.Class==1]))/len(undersample_data[\"Class\"]))\n",
    "    print \"The fraud transacation proportion is : %f\"%fraud\n",
    "    return(undersample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='3f' />\n",
    "##### (f) Genere un modelo de Logistic Regression y otro a su elección utilizando UnderSample. Concluya a partir de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report\n",
    "x_tr,x_ts,y_tr,y_ts = data_prepration(dt)\n",
    "x_tr[\"Class\"] = y_tr[\"Class\"]\n",
    "x_tr = x_tr.reset_index(drop=True)\n",
    "for i in range(1,4):\n",
    "    print \"The undersample data for \" + str(i) + \" proportion\\n\"\n",
    "    Undersample_data = undersample(x_tr,i)\n",
    "    print \"\\n----------------------Validation Set------------------------\"\n",
    "    print \"\\nThe model classification for \" + str(i) + \" proportion\\n\"\n",
    "    under_x,under_xt,under_yx,under_yxt=data_prepration(Undersample_data)\n",
    "    clf=LogisticRegression()\n",
    "    model(clf,under_x,under_xt,under_yx,under_yxt)\n",
    "    print \"--------------------------Testing Set---------------------------\"\n",
    "    model(clf,under_x,x_ts,under_yx,y_ts)\n",
    "    print \"---------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='3g' />\n",
    "##### (g) Vuelva a realizar los puntos (e) y (f), esta vez utilizando OverSampling y SMOTE (Hint: Para SMOTE usted puede apoyarse de la librería imblearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(random_state=0)\n",
    "os_data_X,os_data_y=os.fit_sample(x_tr,y_tr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
